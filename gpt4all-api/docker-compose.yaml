version: "3.8"

services:
  gpt4all_api:
    image: gpt4all_api
    container_name: gpt4all_api
    restart: always #restart on error (usually code compilation from save during bad state)
    ports:
      - "4891:4891"
    environment:
      - APP_ENVIRONMENT=dev
      - WEB_CONCURRENCY=2
      - LOGLEVEL=debug
      - PORT=4891
      - model=ggml-mpt-7b-chat.bin
      - inference_mode=cpu
    volumes:
      - './gpt4all_api/app:/app'
    command: ["/start-reload.sh"]

  gpt4all_gpu:
    image: ghcr.io/huggingface/text-generation-inference
    container_name: gpt4all_gpu
    restart: always #restart on error (usually code compilation from save during bad state)
    environment:
      - HUGGING_FACE_HUB_TOKEN=token
      - USE_FLASH_ATTENTION=false
    command: --model-id ${MODEL_ID} --num-shard ${NUM_SHARD}
    volumes:
      - ./:/data
    ports:
      - "8080:80"
    shm_size: 1g
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]